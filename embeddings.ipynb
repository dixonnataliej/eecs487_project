{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding Similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizerFast, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: {'classifier.bias', 'classifier.weight'}\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE_MODELS = { # which model to use for which language\n",
    "    'malay': 'gte', # can be either\n",
    "    'tibetan': 'labse', # must be labse\n",
    "    'wolof': 'labse', # must be labse\n",
    "    'quechua': 'gte', # must be gte\n",
    "    'spanish': 'gte', # can be either\n",
    "}\n",
    "\n",
    "# Target pairs to compare\n",
    "target_pairs = [\n",
    "    ('official', 'chatgpt'),    \n",
    "    ('official', 'google'),      \n",
    "    ('english', 'roundtrip_chatgpt'),  \n",
    "    ('english', 'roundtrip_google')   \n",
    "]\n",
    "\n",
    "# Model for Malay, Tibetan, Wolof, and Spanish\n",
    "labse_tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "labse_model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "labse_model = labse_model.eval()\n",
    "\n",
    "# Model for Quechua, Malay, Spanish\n",
    "gte_tokenizer = AutoTokenizer.from_pretrained(\"Alibaba-NLP/gte-multilingual-base\")\n",
    "gte_model = AutoModel.from_pretrained(\"Alibaba-NLP/gte-multilingual-base\")\n",
    "gte_model = gte_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(embeddings_1, embeddings_2):\n",
    "    normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "    normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "    return torch.matmul(\n",
    "        normalized_embeddings_1, normalized_embeddings_2.transpose(0, 1)\n",
    "    )\n",
    "\n",
    "def get_embedding(text, model_type, max_length=512):\n",
    "    if model_type == 'labse':\n",
    "        # Spanish, Wolof, Malay, Tibetan\n",
    "        # Tibetan needs to be truncated to 512 tokens or model won't accept it\n",
    "        inputs = labse_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        with torch.no_grad():\n",
    "            outputs = labse_model(**inputs)\n",
    "            return outputs.pooler_output\n",
    "    elif model_type == 'gte':\n",
    "        # Quechua, Malay, Spanish\n",
    "        inputs = gte_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = gte_model(**inputs)\n",
    "            return outputs.last_hidden_state[:, 0, :]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wolof using labse model\n",
      "passage id: 1, similarities: {'official:chatgpt': 0.9103513956069946, 'official:google': 0.9570765495300293, 'english:roundtrip_chatgpt': 0.9767275452613831, 'english:roundtrip_google': 0.9953362345695496}\n",
      "passage id: 2, similarities: {'official:chatgpt': 0.5727707743644714, 'official:google': 0.859481692314148, 'english:roundtrip_chatgpt': 0.9873533844947815, 'english:roundtrip_google': 0.9770512580871582}\n",
      "passage id: 3, similarities: {'official:chatgpt': 0.8564803600311279, 'official:google': 0.9046306610107422, 'english:roundtrip_chatgpt': 0.9779288172721863, 'english:roundtrip_google': 1.0000001192092896}\n",
      "passage id: 4, similarities: {'official:chatgpt': 0.8179197311401367, 'official:google': 0.8423664569854736, 'english:roundtrip_chatgpt': 0.9694747924804688, 'english:roundtrip_google': 0.9845173358917236}\n",
      "passage id: 5, similarities: {'english:roundtrip_chatgpt': 0.8109887838363647, 'english:roundtrip_google': 0.9091354608535767}\n",
      "passage id: 6, similarities: {'english:roundtrip_chatgpt': 0.8889603614807129, 'english:roundtrip_google': 0.9771762490272522}\n",
      "Processing spanish using gte model\n",
      "passage id: 1, similarities: {'official:chatgpt': 0.977511465549469, 'official:google': 0.984632134437561, 'english:roundtrip_chatgpt': 0.9780266880989075, 'english:roundtrip_google': 0.9627983570098877}\n",
      "passage id: 2, similarities: {'official:chatgpt': 0.9531259536743164, 'official:google': 0.9595670104026794, 'english:roundtrip_chatgpt': 0.9754419922828674, 'english:roundtrip_google': 0.9780323505401611}\n",
      "passage id: 3, similarities: {'official:chatgpt': 0.986995279788971, 'official:google': 0.9846200346946716, 'english:roundtrip_chatgpt': 0.9842791557312012, 'english:roundtrip_google': 0.9844852685928345}\n",
      "passage id: 4, similarities: {'official:chatgpt': 0.9786006212234497, 'official:google': 0.9842967391014099, 'english:roundtrip_chatgpt': 0.9704393148422241, 'english:roundtrip_google': 0.9523249268531799}\n",
      "passage id: 5, similarities: {'english:roundtrip_chatgpt': 0.9554601907730103, 'english:roundtrip_google': 0.9385944604873657}\n",
      "passage id: 6, similarities: {'english:roundtrip_chatgpt': 0.9731759428977966, 'english:roundtrip_google': 0.9737626314163208}\n",
      "Processing nahuatl using None model\n",
      "Processing tibetan using labse model\n",
      "passage id: 1, similarities: {'official:chatgpt': 0.8871505856513977, 'official:google': 0.9332752227783203, 'english:roundtrip_chatgpt': 0.9339720010757446, 'english:roundtrip_google': 0.9852234125137329}\n",
      "passage id: 2, similarities: {'official:chatgpt': 0.7222244739532471, 'official:google': 0.7142466902732849, 'english:roundtrip_chatgpt': 0.8495920300483704, 'english:roundtrip_google': 0.9067654609680176}\n",
      "passage id: 3, similarities: {'official:chatgpt': 0.763570249080658, 'official:google': 0.9244461059570312, 'english:roundtrip_chatgpt': 0.8773649334907532, 'english:roundtrip_google': 0.9972203969955444}\n",
      "passage id: 4, similarities: {'official:chatgpt': 0.744825541973114, 'official:google': 0.8869493007659912, 'english:roundtrip_chatgpt': 0.6088777780532837, 'english:roundtrip_google': 0.8818846940994263}\n",
      "passage id: 5, similarities: {'english:roundtrip_chatgpt': 0.7674347758293152, 'english:roundtrip_google': 0.9105829000473022}\n",
      "passage id: 6, similarities: {'english:roundtrip_chatgpt': 0.87217777967453, 'english:roundtrip_google': 0.9495226740837097}\n",
      "Processing quechua using gte model\n",
      "passage id: 1, similarities: {'official:chatgpt': 0.7560768127441406, 'official:google': 0.7464632987976074, 'english:roundtrip_chatgpt': 0.8357802629470825, 'english:roundtrip_google': 0.9861829280853271}\n",
      "passage id: 2, similarities: {'official:chatgpt': 0.8349882364273071, 'official:google': 0.7947797179222107, 'english:roundtrip_chatgpt': 0.8646697998046875, 'english:roundtrip_google': 0.9880257248878479}\n",
      "passage id: 3, similarities: {'official:chatgpt': 0.6687337756156921, 'official:google': 0.6676889061927795, 'english:roundtrip_chatgpt': 0.8777703046798706, 'english:roundtrip_google': 0.9999999403953552}\n",
      "passage id: 4, similarities: {'official:chatgpt': 0.7628563046455383, 'official:google': 0.6504533290863037, 'english:roundtrip_chatgpt': 0.6634945869445801, 'english:roundtrip_google': 0.9408226013183594}\n",
      "passage id: 5, similarities: {'english:roundtrip_chatgpt': 0.7488393187522888, 'english:roundtrip_google': 0.9404260516166687}\n",
      "passage id: 6, similarities: {'english:roundtrip_chatgpt': 0.9047544002532959, 'english:roundtrip_google': 0.9834884405136108}\n",
      "Processing malay using gte model\n",
      "passage id: 1, similarities: {'official:chatgpt': 0.7978379130363464, 'official:google': 0.7988796830177307, 'english:roundtrip_chatgpt': 0.9655980467796326, 'english:roundtrip_google': 0.9959865212440491}\n",
      "passage id: 2, similarities: {'official:chatgpt': 0.9115486145019531, 'official:google': 0.8839519619941711, 'english:roundtrip_chatgpt': 0.9648100733757019, 'english:roundtrip_google': 0.9923780560493469}\n",
      "passage id: 3, similarities: {'official:chatgpt': 0.8344658613204956, 'official:google': 0.8261373043060303, 'english:roundtrip_chatgpt': 0.9553066492080688, 'english:roundtrip_google': 0.9999999403953552}\n",
      "passage id: 4, similarities: {'official:chatgpt': 0.9425380229949951, 'official:google': 0.9371935725212097, 'english:roundtrip_chatgpt': 0.9645750522613525, 'english:roundtrip_google': 0.9841067790985107}\n",
      "passage id: 5, similarities: {'english:roundtrip_chatgpt': 0.9798696637153625, 'english:roundtrip_google': 0.9871374368667603}\n",
      "passage id: 6, similarities: {'english:roundtrip_chatgpt': 0.9787166714668274, 'english:roundtrip_google': 0.989004373550415}\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "for file in os.listdir('translations'):\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "        \n",
    "    language_name = file.split('.')[0]\n",
    "    # all json files should be in the format language_name.json\n",
    "\n",
    "    model_type = LANGUAGE_MODELS.get(language_name)\n",
    "    print(f\"Processing {language_name} using {model_type} model\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join('translations', file), 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                passages = data.get('passages', {})\n",
    "                \n",
    "                if not passages:\n",
    "                    print(\"empty file\")\n",
    "                    continue\n",
    "                \n",
    "                all_results[language_name] = {\n",
    "                    'passage_similarities': {},\n",
    "                    'avg_similarities': {}\n",
    "                }\n",
    "                \n",
    "                all_pair_similarities = {f\"{src}:{tgt}\": [] for src, tgt in target_pairs}\n",
    "                \n",
    "                for passage_id, translations in passages.items():\n",
    "                    passage_sims = {}\n",
    "                    embeddings = {}\n",
    "                    \n",
    "                    for trans_type, text in translations.items():\n",
    "                        if text and text != \"None\" and text.strip(): # Passages with no official translation have \"None\" as the text -- only passages 5/6\n",
    "                            embedding = get_embedding(text, model_type)\n",
    "                            if embedding is not None:\n",
    "                                embeddings[trans_type] = embedding\n",
    "                    \n",
    "                    for src, tgt in target_pairs:\n",
    "                        pair_name = f\"{src}:{tgt}\"\n",
    "                        if src in embeddings and tgt in embeddings:\n",
    "                            sim = float(similarity(embeddings[src], embeddings[tgt]))\n",
    "                            passage_sims[pair_name] = sim\n",
    "                            all_pair_similarities[pair_name].append(sim)\n",
    "                    \n",
    "                    if passage_sims:\n",
    "                        print(f\"passage id: {passage_id}, similarities: {passage_sims}\")\n",
    "                        all_results[language_name]['passage_similarities'][passage_id] = passage_sims\n",
    "                \n",
    "                for pair_name, sims in all_pair_similarities.items():\n",
    "                    if sims:\n",
    "                        all_results[language_name]['avg_similarities'][pair_name] = sum(sims) / len(sims)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from file {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: wolof, avg_sims: {'official:chatgpt': 0.7893805652856827, 'official:google': 0.8908888399600983, 'english:roundtrip_chatgpt': 0.9352389474709829, 'english:roundtrip_google': 0.9738694429397583}\n",
      "language: spanish, avg_sims: {'official:chatgpt': 0.9740583300590515, 'official:google': 0.9782789796590805, 'english:roundtrip_chatgpt': 0.9728038807710012, 'english:roundtrip_google': 0.964999665816625}\n",
      "language: nahuatl, avg_sims: {}\n",
      "nahuatl has empty avg_sims\n",
      "language: tibetan, avg_sims: {'official:chatgpt': 0.7794427126646042, 'official:google': 0.8647293299436569, 'english:roundtrip_chatgpt': 0.8182365496953329, 'english:roundtrip_google': 0.9385332564512888}\n",
      "language: quechua, avg_sims: {'official:chatgpt': 0.7556637823581696, 'official:google': 0.7148463129997253, 'english:roundtrip_chatgpt': 0.8158847788969675, 'english:roundtrip_google': 0.9731576144695282}\n",
      "language: malay, avg_sims: {'official:chatgpt': 0.8715976029634476, 'official:google': 0.8615406304597855, 'english:roundtrip_chatgpt': 0.968146026134491, 'english:roundtrip_google': 0.9914355178674062}\n"
     ]
    }
   ],
   "source": [
    "for language, results in all_results.items():\n",
    "    avg_sims = results['avg_similarities']\n",
    "    print(f\"language: {language}, avg_sims: {avg_sims}\")\n",
    "    if not avg_sims:\n",
    "        print(f\"{language} has empty avg_sims\")\n",
    "        continue\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
